// Exported by storm
// Original model type: MDP
@type: MDP
@parameters

@reward_models

@nr_states
10
@nr_choices
10
@model
state 0 init
//[cell00=0	& cell01=0	& cell02=0	& cell10=0	& cell11=0	& cell12=0	& cell20=0	& cell21=0	& cell22=0	& turn=0]
	action cell11
		1 : 1
state 1
//[cell00=0	& cell01=0	& cell02=0	& cell10=0	& cell11=1	& cell12=0	& cell20=0	& cell21=0	& cell22=0	& turn=1]
	action cell10
		2 : 1
state 2
//[cell00=0	& cell01=0	& cell02=0	& cell10=2	& cell11=1	& cell12=0	& cell20=0	& cell21=0	& cell22=0	& turn=0]
	action cell11
		3 : 1
state 3
//[cell00=0	& cell01=0	& cell02=0	& cell10=2	& cell11=1	& cell12=0	& cell20=0	& cell21=0	& cell22=0	& turn=1]
	action cell22
		4 : 1
state 4
//[cell00=0	& cell01=0	& cell02=0	& cell10=2	& cell11=1	& cell12=0	& cell20=0	& cell21=0	& cell22=2	& turn=0]
	action cell11
		5 : 1
state 5
//[cell00=0	& cell01=0	& cell02=0	& cell10=2	& cell11=1	& cell12=0	& cell20=0	& cell21=0	& cell22=2	& turn=1]
	action cell01
		6 : 1
state 6
//[cell00=0	& cell01=2	& cell02=0	& cell10=2	& cell11=1	& cell12=0	& cell20=0	& cell21=0	& cell22=2	& turn=0]
	action cell11
		7 : 1
state 7
//[cell00=0	& cell01=2	& cell02=0	& cell10=2	& cell11=1	& cell12=0	& cell20=0	& cell21=0	& cell22=2	& turn=1]
	action cell02
		8 : 1
state 8
//[cell00=0	& cell01=2	& cell02=2	& cell10=2	& cell11=1	& cell12=0	& cell20=0	& cell21=0	& cell22=2	& turn=0]
	action cell11
		9 : 1
state 9
//[cell00=0	& cell01=2	& cell02=2	& cell10=2	& cell11=1	& cell12=0	& cell20=0	& cell21=0	& cell22=2	& turn=1]
	action cell02
		8 : 1
