name: openai_gym_training
entry_points:
    main:
        parameters:
            project_name : {type: string, default: "Avoid2"}
            parent_run_id : {type: string, default: ""}
            env : {type: string, default: "avoid:avoid-v0" }
            sliding_window_size : {type: float, default: 100}
            num_episodes : {type: float, default: 50000}
            rl_algorithm : {type: string, default: "sarsamax" }
            # Dummy Agent Parameters
            always_action : {type: float, default: 0}
            # Double DQN Agent
            layers : {type: float, default: 3}
            neurons : {type: float, default: 128}
            replay_buffer_sie : {type: float, default: 1000000}
            epsilon : {type: float, default: 1}
            epsilon_dec : {type: float, default: 0.99999}
            epsilon_min : {type: float, default: 0.01}
            gamma : {type: float, default: 0.99}
            alpha : {type: float, default: 0.8}
            replace : {type: float, default: 128}
            lr : {type: float, default: 0.001}
            batch_size : {type: float, default: 128}
            deploy : {type: float, default : 0}


        command: >-
            python run.py --deploy={deploy} --project_name={project_name} --parent_run_id={parent_run_id} --env={env} --sliding_window_size={sliding_window_size} --num_episodes={num_episodes} --rl_algorithm={rl_algorithm} --always_action={always_action} --layers={layers} --neurons={neurons} --replay_buffer_sie={replay_buffer_sie} --epsilon={epsilon} --epsilon_dec={epsilon_dec} --epsilon_min={epsilon_min} --gamma={gamma} --alpha={alpha} --replace={replace} --lr={lr} --batch_size={batch_size}
